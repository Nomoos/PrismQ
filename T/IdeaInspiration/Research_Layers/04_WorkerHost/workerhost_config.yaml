# PrismQ.Client.WorkerHost Configuration
# Version: 1.0

# ============================================================================
# TaskManager Configuration
# ============================================================================
task_manager:
  # TaskManager type: "http", "amqp", or "redis"
  type: "http"
  
  # API endpoint URL
  url: "https://api.prismq.nomoos.cz/api"
  
  # API authentication key (use environment variable)
  api_key: "${TASKMANAGER_API_KEY}"
  
  # Polling configuration
  poll_interval: 5  # seconds between task polls
  timeout: 30       # HTTP request timeout in seconds
  
  # Retry configuration
  max_retries: 3
  retry_backoff: 2  # exponential backoff multiplier

# ============================================================================
# Worker Definitions
# ============================================================================
workers:
  # YouTube Video Scraper Worker
  - name: "PrismQ.IdeaInspiration.Source.Video.YouTube.VideoScraper"
    description: "Scrapes YouTube videos and saves to IdeaInspiration database"
    
    # Worker location
    project_path: "./Source/Video/YouTube/Video"
    venv_python: "./Source/Video/YouTube/Video/venv/bin/python"
    
    # Worker entrypoint
    module: "src.workers.video_scraper"
    function: "main"
    
    # Task types this worker can handle
    task_types:
      - "PrismQ.YouTube.VideoScrape"
      - "PrismQ.YouTube.VideoAnalysis"
    
    # Execution configuration
    timeout: 300        # 5 minutes max execution time
    max_retries: 3      # retry failed tasks up to 3 times
    
    # Worker metadata
    metadata:
      version: "1.0.0"
      python_version: "3.10"
      dependencies:
        - "youtube-dl"
        - "requests"
      author: "PrismQ Team"
  
  # Reddit Posts Scraper Worker
  - name: "PrismQ.IdeaInspiration.Source.Text.Reddit.PostScraper"
    description: "Scrapes Reddit posts and comments from subreddits"
    
    project_path: "./Source/Text/Reddit/Posts"
    # Windows path example
    venv_python: "./Source/Text/Reddit/Posts/venv/Scripts/python.exe"
    
    module: "src.workers.reddit_scraper"
    function: "main"
    
    task_types:
      - "PrismQ.Reddit.PostScrape"
      - "PrismQ.Reddit.SubredditScrape"
      - "PrismQ.Reddit.CommentScrape"
    
    timeout: 180
    max_retries: 3
    
    metadata:
      version: "1.0.0"
      python_version: "3.11"
      dependencies:
        - "praw"
        - "requests"
  
  # Content Classification Worker
  - name: "PrismQ.IdeaInspiration.Classification.ContentClassifier"
    description: "Classifies content into categories and detects story potential"
    
    project_path: "./Classification"
    venv_python: "./Classification/venv/bin/python"
    
    module: "src.workers.classifier"
    function: "main"
    
    task_types:
      - "PrismQ.Classification.Categorize"
      - "PrismQ.Classification.DetectStory"
    
    timeout: 120
    max_retries: 2
    
    metadata:
      version: "1.0.0"
      python_version: "3.10"
      dependencies:
        - "transformers"
        - "torch"
  
  # Content Scoring Worker
  - name: "PrismQ.IdeaInspiration.Scoring.ContentScorer"
    description: "Scores content quality and engagement potential"
    
    project_path: "./Scoring"
    venv_python: "./Scoring/venv/bin/python"
    
    module: "src.workers.scorer"
    function: "main"
    
    task_types:
      - "PrismQ.Scoring.EvaluateContent"
      - "PrismQ.Scoring.CalculateEngagement"
    
    timeout: 90
    max_retries: 2
    
    metadata:
      version: "1.0.0"
      python_version: "3.10"
      dependencies:
        - "nltk"
        - "textstat"

# ============================================================================
# Logging Configuration
# ============================================================================
logging:
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"
  
  # Log format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  # Log file settings
  file: "logs/workerhost.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5
  
  # Structured logging (JSON format)
  structured: true
  
  # Log worker stdout/stderr
  capture_worker_output: true

# ============================================================================
# Monitoring and Observability
# ============================================================================
monitoring:
  enabled: true
  
  # Prometheus metrics
  metrics:
    enabled: true
    port: 9090
    path: "/metrics"
  
  # Health check endpoint
  health_check:
    enabled: true
    port: 8080
    path: "/health"
  
  # Observability observers
  observers:
    - type: "logging"
      enabled: true
    - type: "metrics"
      enabled: true
    - type: "alerting"
      enabled: false  # Future: integrate with alerting system

# ============================================================================
# Advanced Configuration
# ============================================================================
advanced:
  # Worker pool configuration (future feature)
  worker_pool:
    enabled: false
    min_workers: 1
    max_workers: 5
    idle_timeout: 300
  
  # Resource limits
  resource_limits:
    max_memory_mb: 2048
    max_cpu_percent: 80
  
  # Security
  security:
    validate_worker_paths: true
    allow_environment_variables: true
    restricted_modules: []

# ============================================================================
# Environment-Specific Overrides
# ============================================================================
# These can be overridden via environment variables:
# WORKERHOST_TASKMANAGER_URL
# WORKERHOST_TASKMANAGER_API_KEY
# WORKERHOST_LOGGING_LEVEL
# etc.
